## 〇、Java 性能

- 编译器和垃圾收集器等的调优参数
- API 的最佳实践



## 一、Java 调优工具

- jps：查看 Java 虚拟机的进程
- jmap：查看虚拟机的内存转储快照
- jstat：查看虚拟机统计信息
- jinfo：查看虚拟机配置信息
- jstack：查看虚拟机的线程快照



## 二、性能测试方法（4 项原则）

### 原则1：测试真实应用

- 微基准测试
- 宏基准测试
- 介基准测试

### 原则2：理解批处理流逝时间、吞吐量和响应时间

- 批处理流逝时间：完成任务花了多少时间

- 吞吐量测试是基于一段时间内所能完成的工作量。

- 响应时间：从客户端发送请求至收到响应之间的流逝时间。



小结：

1. Java性能测试中很少使用面向批处理的测试（或者任何没有热身期的测试），但这种测试可以产生很有价值的结果。
2. 其他可以测量吞吐量或响应时间的测试，则依赖负载是否以固定的速率加载（也就是说，基于模拟的客户端思考时间）。

### 原则3：用统计方法应对性能的变化



- 因代码更改而进行的测试称为回归测试



### 原则4：尽早频繁测试

- 自动化一切
  - 所有的性能测试都应该脚本化（程序化）
  - 脚本必须能够多次运行测试，对结果进行t检验分析，并能生成置信度报告，说明统计结果是相同，还是不同，如果不同，相差多少。
- 测试一切
  - 数据包括整个运行过程中采集的系统信息：CPU使用率、磁盘使用率、网络使用率和内存使用率等。
  - 数据还包括应用的日志——应用产生的日志，以及垃圾收集器的日志。
  - 周期性线程堆栈、其他堆分析数据
- 在真实系统上运行
  - 机器规模越大，同时能运行的线程就越多，从而能减少应用线程对CPU的竞争。与此同时，大规模系统也会遇到小型笔记本上会被忽略的同步性能瓶颈。





## 三、Java 性能调优工具



### 操作系统的工具和分析

- CPU 使用率

  - 用户态时间：CPU 执行应用代码所占时间的百分比

  - 系统态时间：CPU 执行内核代码所占时间的百分比

  - 常用 Linux 命令

    ```bash
    # 查看内存、CPU、磁盘 IO 的使用情况
    vmstat -a 2 5
    ```

  - 优化代码的目的：提升 CPU 使用率

- 磁盘使用率

  - 如果应用正在做大量的磁盘I/O操作，那I/O就很容易成为瓶颈。

  - 有助于监控系统是否在进行内存交换

  - 常用 Linux 命令

    ```bash
    iostat 2 3
    ```

- 网络使用率

  - 网络使用率类似磁盘流量：应用可能没有充分利用网络所以带宽很低，或者写入某网络接口的总数据量超过了它所能处理的量。

  - 常用 Linux 命令

    ```bash
    # 显示网卡列表
    netstat -i
    # 
    netstat -lntup
    
    # 显示网络统计
    netstat -s | more -5
    
    # 显示路由信息
    netstat -r
    
    # 统计机器中网络连接各个状态个数
    netstat -an |awk '/^tcp/ {++S[$NF]} END {for (a in S) print a,S[a]}'
    # 把状态全都取出来后使用 uniq -c 统计后再进行排序
    netstat -ant|awk '{print $6}'|sort|uniq –c
    # 查看连接某服务端口最多的的 IP 地址
    netstat -ant|grep "192.168.25.*"|awk '{print $5}'|awk -F: '{print $1}'|sort -nr|uniq –c
    # 找出程序运行的端口
    netstat -ap | grep ssh
    ```

    

### Java 监控工具

- jcmd：用来打印 Java 进程所涉及的基本类、线程和 VM 信息

  ```bash
  # 运行时间
  jcmd pid VM.uptime
  # 系统属性
  jcmd pid VM.system_properties
  jinfo -sysprops pid
  # JVM 版本
  jcmd pid VM.version
  # JVM 命令行（VM Arguments）
  jcmd pid VM.command_line
  # JVM 调优标志(参数)
  jcmd pid VM.flags [-all]
  # 获取栈信息
  jcmd pid Thread.print
  ```

- jconsole：提供JVM活动的图形化视图，包括线程的使用、类的使用和GC活动。

- jstat：提供 GC 和类装载活动的信息。可适用于脚本。

- jps：查看 Java 虚拟机的进程

- jmap：查看虚拟机的内存转储快照

- jinfo：查看虚拟机配置信息

  - 允许程序在执行时更改某个标志的值。

  ```bash
  # 获取进程中所有标志的值
  jinfo -flags pid
  # 检查单个标志的值
  jinfo -flag PrintGCDetails pid
  ```

  

- jstack：查看虚拟机的线程快照



#### 

### 性能分析工具



- 数据采样
- 数据探查



### Java 任务控制(JMC+JFR)

1. 由于 JFR 内建于 JVM，所以可以最大可能地查看 JVM 内部。
2. 像其他工具一样，JFR 给应用引入了一些开销。对于日常使用，可以开启 JFR，以较低的开销收集大量信息。
3. JFR 用于性能分析，但它在生产系统中也很有用，所以你可以检查那些导致失败的事件。

#### 事件类型

- Classloading
  - 装载或卸载的类的数量
  - 哪个类装载器装载的类，装载单个类需要的时间
- Thread statistics
  - 创建和销毁的线程数，线程转储
  - 被锁阻塞的线程（以及阻塞住它们的特定锁）
- Throwables
  - 应用所用的异常错误类
  - 有多少异常和错误被抛出了，以及它们生成时的栈追踪信息
- TLAB allocation
  - 堆分配的数量和本地线程分配缓冲的大小
  - 堆中分配的对象和分配它们的栈追踪信息
- File and socket I/O
  - 执行I/O所用的时间
  - 每次读/写调用所用的时间，读或写很长时间的特定文件或socket
- Monitor blocked
  - 等待管程的线程
  - 在特定管程上阻塞的线程以及它们被阻塞的时间
- Code cache
  - 代码缓存的大小以及包含多少量
  - 从代码缓存中移走的Java方法，代码缓存配置
- Code compilation
  - 哪个方法已被编译，OSR编译和编译的时长
  - 除了JFR其他工具也包括的信息，但这是从多个源头获取的统一信息
- Garbage collection
  - GC的时间，包括单个阶段，代的大小
  - 除了JFR其他工具也包括的信息，但这是从多个工具获取的统一信息
- Profiling
  - 探查和采样分析器
  - 不像真的性能分析器那样有很多信息，但JFR分析器提供了很好的更高层次的概要信息



## 四、JIT 编译器

- 

### 编译器类型

- client 编译器（32位）：-client
- server 编译器
  - 32位：-server
  - 64位：-d64
- **分层编译（java8 后默认启动）**：
  - 启动时使用 client 编译器，执行达到阈值时使用 server 编译器

#### 优化启动

1. 如果应用的启动时间是首要的性能考量，那 client 编译器就是最有用的。
2. 分层编译的启动时间可以非常接近于 client 编译器所获得的启动时间。

#### 优化批处理

- 分层编译是批处理任务合理的默认选择。

#### 优化长时间运行的应用

- 对于长时间运行的应用来说，应该一直使用 server 编译器，最好配合分层编译。



### 选择 jvm 版本

- **如果堆小于 3 GB，32 位的 Java 会更快一些，并且内存占用也更少。**这是因为 JVM 内部的指针只有 32 位，**操作 32 位指针的代价要少于 64 位指针**的（即便你使用的是 64 位 CPU）。而且 32 位指针**所占的内存也少**。

  - 不足之处：进程最多只能占用 4 GB 内存
  - 32 位 JVM 无法使用 CPU 的 64 位寄存器，所以大量使用 long 或 double 变量的程序在 32 位 JVM 上就会比较慢。

- 编译器的选择取决于安装的JVM是 32 位还是 64 位，以及传递给 JVM 的编译器参数。

  ![](images/不同JVM安装版本和不同参数下的编译器.jfif)



### 编译器中级调优

- 大多数情况下，编译器调优只是为目标机器上的 Java **选择正确的 JVM 和编译器开关**（-client、-server 或 -XX:+TieredCompilation）。**分层编译**通常是长期运行应用的最佳选择。



#### 调优代码缓存

- 代码缓存是一种有最大值的资源，它会影响JVM可运行的编译代码总量。
- 分层编译很容易达到代码缓存默认配置的上限（特别是在 Java 7 中）。使用分层编译时，应该监控代码缓存，必要时应该增加它的大小。



#### 编译阈值

- 如果循环的回边计数器超过阈值，那这个循环（不是整个方法）就可以被编译。这种编译称为栈上替换（On-Stack Replacement,OSR）。
- 改变阈值会导致代码提早或推后编译。
- 由于计数器会随着时间而减少，以至于“温热”的方法可能永远都达不到编译的阈值（特别是对 server 编译器来说）



#### 检测编译过程

- 常用 Linux 命令

  ```bash
  # 有多少方法被编译的概要信息
  jstat -compiler pid
  
  # 获取最近被编译的方法
  jstat -printcompilation pid
  ```

- 观察代码如何被编译的最好方法是开启 PrintCompilation

- PrintCompilation 开启后所输出的信息可用来确认编译是否和预期一样



### 高级编译器调优

- 编译线程
  - 放置在编译队列中的方法的编译会被异步执行。
  - 队列并不是严格按照先后顺序的；队列中的热点方法会在其他方法之前编译。这是编译输出日志中的 ID 为乱序的另一个原因。
- **方法内联**
  - 编译器所做的最重要的优化是方法内联。特别是对属性封装良好的面向对象的代码来说。
- 逃逸分析
  - 逃逸分析是编译器能做得最复杂的优化。此类优化常常会导致微基准测试失败。
  - 逃逸分析常常会给不正确的同步代码引入“bug”。

### 逆优化

- 逆优化使得编译器可以回到之前版本的编译代码。
- 先前的优化不再有效时（例如，所涉及的对象类型发生了更改），才会发生代码逆优化。
- 代码逆优化时，会对性能产生一些小而短暂的影响，不过新编译的代码会尽快地再次热身。
- **分层编译时，如果代码之前由 client 编译器编译而现在由 serve r编译器优化，就会发生逆优化。**
  - 分层编译可以在两种编译器和5种级别之间进行
  - 不建议人为更改级别，本节仅仅是辅助解释编译日志的输出。



## 五、垃圾收集器



### GC调优基础

- 调整堆的大小（trade-off）

  - 设置总体堆的大小

    - 堆过小：程序的大部分时间可能都消耗在 GC 上，没有足够的时间去运行应用程序的逻辑

    - 堆过大：GC 停顿消耗的时间取决于堆的大小，如果增大堆的空间，停顿的持续时间也会变长

    - **通常情况下，对于普通的操作系统，应该预留至少 1G 的内存空间。**

    - jvm 参数

      ```bash
      # 初始堆的大小
      -Xms8G
      # 最大堆的大小
      -Xmx8G
      ```

- 代空间的调整（trade-off）

  - 如果新生代分配得比较大，垃圾收集发生的频率就比较低，从新生代晋升到老年代的对象也更少。

  - jvm 参数

    ```bash
    # 设置新生代与老年代的空间占用比率。
    -XX:NewRatio=N
    # 设置新生代空间的初始大小。
    -XX:NewSize=N
    # 设置新生代空间的最大大小。
    -XX:MaxNewSize=N
    # 将 NewSize 和 MaxNewSize 设定为同一个值的快捷方法。
    -XmnN
    ```

- 永久代和元空间的调整

  - 保存了大量与类相关的数据。以分离的堆的形式存在。

  - jvm 参数

    ```bash
    # 永久代:调整大小(Java 7)
    -XX:PermSize=N
    -XX:MaxPermSize=N
    # 元空间:调整大小(Java 8)
    -XX:MetaspaceSize=N
    -XX:MaxMetaspaceSize=N
    # 设置元空间的上限
    MaxMetaspaceSize
    ```

- 控制并发

  - jvm 参数

    ```bash
    # 启动线程数
    -XX:ParallelGCThreads=N
    
    ```

  - 总的线程数：ParallelGCThreads = 8 + ((N - 8) * 5 / 8)；N 为 CPU 的数目

- 自适应调整

  - JVM 在堆的内部如何调整新生代及老年代的百分比是由自适应调整机制控制的。
  - 通常情况下，我们应该开启自适应调整，因为垃圾回收算法依赖于调整后的代的大小来达到它停顿时间的性能目标。
  - 对于已经精细调优过的堆，关闭自适应调整能获得一定的性能提升。



### 垃圾回收工具（GC 日志）

- 开启 GC 的日志功能

  ```bash
  # 创建基本的 GC 日志
  -verbose:gc
  -XX:+PrintGC
  # 创建更详细的 GC 日志
  -XX:+PrintGCDetails
  # 便于我们更精确地判断几次 GC 操作之间的时间
  -XX:+PrintGCTimeStamps
  -XX:+PrintGCDateStamps
  # 修改输出到某个文件
  -Xloggc:filename
  # 使用日志循环（Log rotation）标志可以限制保存在GC日志中的数据量（默认关闭）
  -XX:+UseGCLogfileRotation 
  -XX:NumberOfGCLogfiles=N
  -XX:GCLogfileSize=N			（日志文件的大小最小为 8 KB）
  ```

- jstat 工具

  ```bash
  # 输出消耗在 GC 上的时间，以及每个 GC 区域使用的百分比(每隔 2 秒输出)
  jstat -gcutil pid 2000
  
  # 输出解析：
  YGC：minor gc 的总次数		YGCT：minor gc 花费的总时间
  FGC：full gc 的次数			FGCT：full gc 的总时间
  S0/S1：Survivor 空间的容量占比
  E：Eden 空间的容量占比
  O：老年代空间使用率
  P：永久代空间使用率
  
  ```







## 六、垃圾收集调优

### Throughput 收集器（Parallel）

- 两个基本操作：
  - 回收新生代的垃圾
  - 回收老年代的垃圾。

- jvm 标志

```bash
# 设定应用可承受的最大停顿时间，MaxGCPauseMillis 标志的优先级最高
-XX:MaxGCPauseMillis=N
# 设置你希望应用程序在垃圾回收上花费多少时间
-XX:GCTimeRatio=N

ThroughputGoal = 1 - 1 / (1 + GCTimeRatio)
GCTimeRatio = Throughtput / (1 - Throughput)
```

### CMS 收集器

- 三种基本操作：

  - 对新生代的对象进行回收（所有的应用线程都会被暂停）
  - 启动一个并发的线程对老年代空间的垃圾进行回收
  - CMS 会发起 Full GC

- CMS 垃圾回收有多个操作，但是期望的操作是 Minor GC 和并发回收（concurrent cycle）。

- CMS 收集过程中的**并发模式失效**以及**晋升失败的代价**都非常昂贵；我们应该尽量调优 CMS 收集器以避免发生这些情况。

  - 新生代发生垃圾回收，同时老年代又没有足够的空间容纳晋升的对象时，CMS垃圾回收就会退化成Full GC（单线程）
  - 老年代有足够的空间可以容纳晋升的对象，但是由于空闲空间的碎片化，导致晋升失败。CMS收集器在新生代垃圾收集过程中（所有的应用线程都被暂停时），对整个老年代空间进行了整理和压缩。（长达 28 秒）

- 默认情况下 CMS 收集器不会对永久代进行垃圾回收。

- jvm 标志

  ```bash
  # 确定使用多大的堆和多大的代空间。
  MaxGCPauseMllis=N
  GCTimeRatio=N
  ```

- 除非发生 Full GC，否则 CMS 的新生代大小不会作调整

#### 针对并发模式失效的调优

- 想办法**增大老年代空间**，要么只移动部分的新生代对象到老年代，要么**增加更多的堆空间**。

- 以更高的频率运行后台回收线程。 ===> 调整 CMSInitiatingOccupancy-Fraction 参数，尽早启动并发后台线程的运行。

  ```bash
  # CMS会在老年代空间占用达到 N% 时启动并发收集周期
  -XX:CMSInitiatingOccupancyFraction=N
  # CMS就只依据设置的老年代空间占用率来决定何时启动后台线程
  -XX:+UseCMSInitiatingOccupancyOnly
  ```

- **使用更多的后台回收线程**。

  - 调整这一标志的要点在于判断是否有可用的CPU周期

  ```bash
  # 增加 CMS 后台线程的数目
  -XX:ConcGCThreads=N
  # 默认情况
  ConcGCThreads = (3 + ParallelGCThreads)  / 4
  ```

  

#### CMS 收集器的永久代调优

- jvm 标志

  ```bash
  # 永久代中的垃圾使用与老年代同样的方式进行垃圾收集：通过一组后台线程并发地回收永久代中的垃圾对象。
  -XX:+CMSPermGenSweepingEnabled
  # 指定CMS收集器在永久代空间占用比达到设定值时启动永久代垃圾回收线程，这个参数的默认值为 80%
  -XX:CMSInitiatingPermOccupancyFraction=N
  # 真正释放不再被引用的类
  -XX:+CMSClassUnloadingEnabled
  ```

  

#### 增量式 CMS 垃圾收集

- 在 Java 8 中已经不推荐使用了，不过暂时还保留在其中，但是在 Java 9 中很可能会被移除。

- jvm 标志

  ```bash
  # 开启增量式CMS垃圾收集
  -XX:+CMSIncrementalMode
  # 控制垃圾收集后台线程为应用程序线程让出多少CPU周期。
  -XX:CMSIncrementalSafetyFactor=N
  -XX:CMSIncrementalDutyCycleMin=N
  -XX:CMSIncrementalPacing
  ```

- 应用在 **CPU 资源受限的机器**上运行，同时又要求较小的停顿，这时使用增量式 CMS 收集器是一个不错的选择。

- 通过责任周期可以调整增量式 CMS 收集器；增加责任周期的运行时间可以避免 CMS 收集器发生并发模式失效。





### G1 收集器

- G1收集器的收集活动主要包括4种操作
  - 新生代垃圾收集；
  - 后台收集，并发周期；
  - 混合式垃圾收集；
  - 以及必要时的 Full GC。
- 快速小结
  - G1垃圾收集包括多个周期（以及并发周期内的阶段）。调优良好的JVM运行G1收集器时应该只经历新生代周期、混合式周期和并发GC周期。
  - G1的并发阶段会产生少量的停顿。
- 避免发生 Full GC
  - 作为G1收集器调优的第一步，首先应该**设定一个合理的停顿时间作为目标**。
  - 通过增加总的堆空间大小或者调整老年代、新生代之间的比例来增加老年代空间的大小。
  - 增加**后台线程的数目**（假设我们有足够的CPU资源运行这些线程）。
  - 以**更高的频率**进行G1的后台垃圾收集活动。
  - 在**混合式垃圾回收周期**中完成更多的垃圾收集工作。



### 高级调优





#### 晋升及 Survivor 空间

- 新生代晋升到老年代的两种情况：
  1. Survivor 空间的大小实在太小
  2. 对象在 Survivor 空间中经历的 GC 周期数超过晋升阈值(Tenuring Threshold)
- 避免频繁发生新生代晋升
  - 增大堆的大小（至少增大新生代的）
  - 减小存活率

#### 分配大对象

- “大型”是一个相对的概念，取决于 JVM 内的“线程本地分配缓冲池”（Thread Local Allocation Buffer，TLAB）

- TLAB

  - 默认情况下，TLAB 的大小由三个因素决定：**应用程序的线程数、Eden 空间的大小以及线程的分配率**。

  - 受益于 TLAB 参数调整的应用程序：

    1. 需要分配大量巨型对象的应用程序
    2. 对于 Eden 空间的大小而言，应用程序线程数量过多的应用

  - 如果发现大量的对象分配发生在 TLAB 之外，我们有两种选择

    1. 减小分配对象的大小
    2. 调整 TLAB 的参数。

  - JVM 标志

    ```bash
    # 每次新生代垃圾收集时，GC 日志中就同时包含了两种类型的信息：每个线程都有一行描述该线程的 TLAB 使用情况，以及一行摘要信息，描述 JVM 整体的 TLAB 使用情况。
    -XX:+PrintTLAB
    ```

- 调整 TLAB 的大小

  - 由于 TLAB 的大小基于 Eden 空间，通过参数调整（增大）Eden 空间会自动增大 TLAB 的大小。

  - JVM 标志

    ```bash
    # 显式地指定 TLAB 的初始大小（默认动态计算）
    -XX:TLABSize=N
    # 是否调整 TLAB 的大小
    -XX:-ResizeTLAB
    ```

- 使用 G1 收集器分配巨型对象

  - G1分区的大小是2的幂，最小值为1 MB。
  - 如果堆的初始大小跟最大值相差很大，这种堆会有大量的G1分区，在这种情况下，应该增大G1分区的大小。
  - 如果要分配的对象大小超过了G1收集器分区容量的一半，对于这种应用程序，我们应该增大G1分区的容量，让G1分区能更好地适配这些对象。遵循这个原则，应用程序分配对象的大小至少应是512 KB（因为G1分区的最小值为1 MB）。



#### AggressiveHeap 标志

- 这个标志只适用于64位的JVM。
- 可能不再适用。



#### 全盘掌控堆空间的大小

- 堆的默认大小依据机器的内存配置确定，也可以通过参数 -XX:MaxRAM=N 设置。



### 小结

- 



## 七、堆内存最佳实践

### 堆分析



#### 堆直方图

- Linux 命令

  ```bash
  # 查看堆直方图
  jcmd pid GC.class_histogram | more
  jmap -histo pid | more
  # 
  ```

  

#### 堆转储

- Linux 命令

  ```bash
  # jcmd 默认加上 live
  jcmd pid GC.heap_dump /path/to/heap_dump.hprof
  # 在 jmap 中包含 live 选项，这会在堆被转储之前强制执行一次 Full GC
  jmap -dump:live, file=/path/to/heap_dump.hprof pid
  ```

- 打开 hprof 文件的工具

  - jhat：最原始的堆分析工具
  - jvisualvm：可以浏览堆，检查最大的保留对象，以及执行任意针对堆的查询。
  - mat：可以生成报告，向我们建议可能存在问题的地方；也可以用于浏览堆，并对堆执行类 SQL 的查询。

- 如果堆分析工具表明有些对象支配着大部分堆，那事情就好办了：我们需要做的就是少创建一些这类对象，减少保留这类对象的时间，简化其对象图，或者将对象变小。



#### 内存溢出错误

- 抛出内存溢出错误(OutOfMemoryError)的情况：

  - JVM 没有原生内存可用
  - 永久代（在Java 7和更早的版本中）或元空间（在Java 8中）内存不足
    - 应用使用的类太多：增加永久代的大小
    - 涉及类加载器的内存泄漏：在直方图中，找到 ClassLoader 类的所有实例，然后跟踪它们的 GC 根，看一下哪些对象还保留了对它们的引用。
  -  Java 堆本身内存不足——对于给定的堆空间而言，应用中活跃对象太多
    - 持续分配新对象，却没有让其他对象退出作用域：**堆转储分析**，集中到减少那些对象的数目（或大小）上
  - JVM 执行 GC 耗时太多(满足下列所有条件时就会抛出该错误)：
    - 花在Full GC上的时间超出了-XX:GCTimeLimit=N标志指定的值。其默认值是98（也就是，如果98%的时间花在了GC上，则该条件满足）。
    - 一次Full GC回收的内存量少于-XX:GCHeapFreeLimit=N标志指定的值。其默认值是2，这意味着如果Full GC期间释放的内存不足堆的2%，则该条件满足。
    - 上面两个条件连续5次Full GC都成立（这个数值是无法调整的）。
    -  -XX:+UseGCOverhead-Limit标志的值为true（默认如此）

- JVM 标志

  ```bash
  # 该标志默认为 false，打开该标志，JVM 会在抛出 OutOfMemoryError 时创建堆转储。
  -XX:+HeapDumpOnOutOfMemoryError
  # 指定了堆转储将被写入的位置；默认会在应用的当前工作目录下生成 java pid<pid>.hprof 文件。这里的路径可以指定目录（这种情况下会使用默认的文件名），也可以指定要生成的实际文件的名字。
  -XX:HeapDumpPath=<path>
  # 在运行一次 Full GC 后生成一个堆转储文件。
  -XX:+HeapDumpAfterFullGC
  # 在运行一次 Full GC 之前生成一个堆转储文件。
  -XX:+HeapDumpBeforeFullGC
  ```



### 减少内存使用



- 高效使用内存的方式。

#### 减少对象大小

- 让对象变小。
  - 减少实例变量的个数（效果很明显）
  - 减少实例变量的大小（效果没那么明显）
- 对象大小未必总能很明显地看出来：**对象会被填充到 8 字节的边界**，对象引用的大小在 32 位和 64 位 JVM 上也有所不同。
- 对象内部即使**为 null 的实例变量**也会占用空间。

#### 对象的延迟初始化

- 只有当常用的代码路径不会初始化某个变量时，才去考虑延迟初始化该变量。

- 单例模式：延迟初始化
- 尽早清理：通过将变量的值设置为 null，实现尽早清理，从而使问题中的对象可以更快地被垃圾收集器回收。

#### 使用规范化对象（不可变对象和标准化对象）



- 创建标准化对象
  - 字符串：调用 intern() 方法找到该字符串的一个标准化版本
  - 要知道**是不是有大量重复的字符串**，需要对堆进行一些分析。



### 对象生命周期管理



#### 对象重用

- 方式：
  - 对象池
  - 线程局部变量
- 重用对象的例子：
  - 线程池：线程初始化的成本很高
  - JDBC 池：数据库连接初始化的成本很高
  - EJOB 池：EJB 初始化的成本很高。
  - 大数组：Java要求，一个数组在分配的时候，其中的每个元素都必须初始化为某个默认值（null、0或者false，根据具体情况而定）。对于很大的数组，这是非常耗时的。
  - 原生 NIO 缓冲区（缓冲区池）：不管缓冲区多大，分配一个直接的java.nio.Buffer（即调用allocateDirect()方法返回的缓冲区），这个操作都非常昂贵。最好是创建一个很大的缓冲区，然后通过按需切割的方式来管理，以便将其重用于以后的操作。
  - 安全相关类：MessageDigest、Signature以及其他安全算法的实例，初始化的成本都很高。基于Apache的XML代码就是使用线程局部变量保存这些实例的。
  - 字符串编解码器对象：JDK中的很多类都会创建和重用这些对象。
  - StringBuilder 协助者：BigDecimal 类在计算中间结果时会重用一个 StringBuilder 对象。
  - 随机数生成器：Random 类和（特别是）SecureRandom 类，生成它们的实例的代价是很高的。
  - 从 DNS 查询到的名字：网络查询代价很高。
  - ZIP 编解码器：初始化的开销不是特别高，但是释放的成本很高，因为这些对象要依赖对象终结操作（finalization）来确保释放掉所用的原生内存。
- 对象池的性能影响因素：
  - GC 影响：保存大量对象会降低 GC 的效率（有事非常显著）
  - 同步：对象池必然是同步的，如果对象要频繁地移除和替换，对象池上可能会存在大量竞争。其结果是，访问对象池可能比初始化新对象还慢。
  - 限流：对于对稀缺资源的访问，线程池可以起到限流作用。
- 线程局部变量的性能影响因素：
  - 生命周期管理：线程局部变量要比在池中管理对象更容易，成本更低。线程局部对象在线程内总是可用的，不需要显式地归还。
  - 基数性：线程局部变量通常会伴生线程数与保存的可重用对象数之间的一一对应关系。**保存的对象数不可能会超过线程数，大部分时间两者是相同的。**
  - 同步：线程局部变量不需要同步，因为它们只能用于一个线程之内；而且线程局部的get()方法相当快。
- 如何选择？
  - 对象池：应用于初始化成本高昂，以及重用对象的数目比较小
  - 线程局部变量：建设线程和可重用对象直接存在一一对应关系



#### 弱引用、软引用与其他引用

- jvm 标志

  ```bash
  # 查看处理所有的引用花了多少时间
  XX:+PrintReferenceGC
  ```

- 软引用：

  - 如果对象的数目不是特别大，软引用就会工作得很好。否则，就要考虑用更传统的、固定大小的对象池来实现一个 LRU 缓存。

- 弱引用：

  - 非确定引用与集合
    - 非确定引用对垃圾收集器有不利影响
    - 类本身必须周期性地执行一个操作，清理集合中所有的未引用数据

- 终结器（Finalizer）和最终引用（Final Reference）

  - 如果使用终结器是不可避免的，那么一定要确保尽量减少该对象访问的内存。



- 小结：
  - 非确定引用（包括软引用、弱引用、虚引用和最终引用）会改变Java对象正常的生命周期，与池或线程局部变量相比，它可以以对GC更为友好的方式实现对象重用。
  - 当应用对某个对象感兴趣，而且该对象在应用中的其他地方有强引用时，才应该使用弱引用。
  - 软引用保存可能长期存在的对象，提供了一个简单的、对GC友好的LRU缓存。
  - 非确定引用自身会消耗内存，而且会长时间抓住其他对象的内存；应该谨慎使用。







## 八、原生内存（操作系统）最佳实践



### 内存占用



- 原生 NIO 缓冲区：

  - 调用 allocateDirect() 方法非常昂贵，所以应该**尽可能重用直接字节缓冲区**。

  - jvm 标志：

    ```bash
    # 设置 直接字节缓冲区所分配的内存总量 最大值
    -XX:MaxDirectMemorySize=N
    
    # 开启原生内存跟踪；summary：概括信息
    -XX:NativeMemoryTracking=off|summary|detail
    # 通过 jcmd 命令获得原生内存信息
    jcmd pid VM.native_memory summary
    
    # 在程序退出时打印原生内存分配信息
    -XX:+PrintNMTStatistics
    ```

- 从调优角度看，要控制 JVM 的内存占用，可以限制用于直接字节缓冲区、线程栈和代码缓存的原生内存（以及堆）的使用量。

- 原生内存跟踪（NMT）

  - 总提交大小：进程的总提交大小，是该进程将要消耗的实际物理内存量。
  - 每部分的提交大小：用于调优堆、代码缓存或元空间等不同部分的最大值。

- NMT 跟踪

  - Linux 命令

    ```bash
    # 确定内存的基线使用情况
    jcmd pid VM.native_memory bashline
    
    # 比较 JVM 当前的内存分配情况与基线的差别
    jcmd pid VM.native_memory summary.diff
    ```

    



### 操作系统优化 JVM

- 大页

  - 操作系统分配的页数一般要比物理内存能容纳的页数多很多，这就是存在分页机制的原因：**地址空间中的页会被移入或移出交换空间**。这些页和它们在计算机物理内存中所占的位置间存在某种映射。

  - 这些映射有两种不同的处理方式。

    - 所有的页映射都保存在一个**全局页表**中（操作系统可以扫描这个表，找到特定的映射）
    - 最常用的映射保存在 **TLB**（Translation Lookaside Buffers）中。TLB 保存在一个快速的缓存中，所以通过 TLB 表项访问页要比通过页表访问快得多。

  - 机器中 TLB 表项的数目有限，TLB 会用作 LRU（Least Recently Used，最近最少使用的）缓存，因此**最大化 TLB 表项的命中率就变得非常重要**。

  - JVM 标志

    ```bash
    # 启用大页
    -XX:+UseLargePages
    ```

  - Linux 大页(配置繁琐)

    ```bash
    # 确定内核支持哪些大页大小
    grep Hugepagesize /proc/meminfo
    
    # 计算需要多少大页（堆内存 / hugepagesize)
    ```

  - Linux 透明大页

    ```bash
    # always [madvise] never
    cat /sys/kernel/mm/transparent_hugepage/enabled
    # [always] madvise never
    echo always > /sys/kernel/mm/transparent_hugepage/enabled
    ```

    - 这会影响该系统上的 JVM 和其他任何程序；它们运行的时候都会使用大页。

  - **如果启用了透明大页，就不要指定 UseLargePages 标志。如果显式地设置了该标志，JVM 会使用传统的大页；如果没有配置好传统的大页，则使用标准页。如果该标志设置为默认值，则 JVM 会使用透明大页（如果已经配置）。**



### 压缩的 oop

- 对于同一任务，32 位 JVM 的性能要比 64 位 JVM 的好 5%~20%。**性能差距是 64 位的对象引用导致的。主要原因是，在堆中，32 位的对象引用占 4 字节，而64 位的对象引用占 8 字节，是前者的 2 倍。这就致使需要更多 GC 周期，因为堆中留给其他数据的空间少了**。

- JVM 可以使用压缩的 oop 来弥补额外的内存消耗。

  - oop：ordinary object pointer，普通对象指针，JVM 将其用作对象引用的句柄。

- 两点启示：

  1. 对于大小在 4 GB 和 32 GB 之间的堆，应该使用压缩的 oop
  2. 使用了 31 GB 的堆，并启用压缩 oop 的程序，通常要快于使用了 33 GB 的堆的程序。尽管后者的堆更大，但是堆中的指针要占据额外的空间，这意味着更大的堆执行 GC 的频率会更频繁，性能也更差。

- 最好是使用**小于 32 GB** 的堆空间，或者使用**比 32 GB 至少多若干 GB** 的堆空间。对象引用会占用 20% 的堆空间，所以 38 GB 是个不错的起点。

- JVM 标志

  ```bash
  # 启用压缩的 oop(在Java 7和更新的版本中，只要堆的最大值小于32 GB，压缩的oop默认就是启用的)
  -XX:+UseCompressedOops
  ```

- 启用 CompressOops 后，会压缩的对象：
  - 每个 Class 的属性指针（静态成员变量）
  - 每个对象的属性指针
  - 普通对象数组的每个元素指针
- 指向 PermGen 的 Class 对象指针，本地变量，堆栈元素，入参，返回值，NULL 指针不会被压缩
- CompressedOops 原理
  - 64 位地址分为堆的基地址+偏移量，当堆内存 < 32GB 时候，在压缩过程中，把 偏移量/8 后保存到 32 位地址。在解压时再把 32 位地址放大 8 倍，所以启用 CompressedOops 的条件是**堆内存要在 4GB*8 = 32GB 以内**
  - CompressedOops，可以让跑在 64 位平台下的 JVM，不需要因为更宽的寻址，而付出 Heap 容量损失的代价。 不过它的实现方式是在机器码中植入压缩与解压指令，可能会给 JVM 增加额外的开销。
- 总结：
  - 如果 GC 堆大小在 4G 以下，直接砍掉高 32 位，避免了编码解码过程；
  - 如果 GC 堆大小在 4G 以上 32G 以下，则启用 UseCompressedOop；
  - 如果 GC 堆大小大于 32G，压指失效，使用原来的 64 位。





## 九、线程与同步的性能



### 线程池与 ThreadPoolExecutor



- 线程池的工作方式

  > 所有线程池的工作方式本质是一样的：
  >
  > 1. 有一个队列，任务被提交到这个队列中。（可以有不止一个队列，概念是一样的。）
  > 2. 一定数量的线程会从该队列中取任务，然后执行。
  > 3. 任务的结果可以发回客户端（比如应用服务器的情况下），或保存到数据库中，或保存到某个内部数据结构中，等等。
  > 4. 但是在执行完任务后，这个线程会返回任务队列，检索另一个任务并执行（如果没有更多任务要执行，该线程会等待下一个任务）。

- 设置最大线程数

  - 与 CPU 数目相同
  - 一般来说，线程有可能会调用数据库，或者把输出写到某个地方，甚至是会合其他某些资源。在那种情况下，瓶颈未必是CPU，而可能是外部资源。
  - 如果还向瓶颈处增加负载，性能会显著下降。相反，如果减少了当前瓶颈处的负载，性能可能会上升。
  - 设置最大线程数更像是艺术而非科学，不只要考虑 CPU，还要考虑外部资源性能瓶颈。

- 设置最小线程数

  -  通常设置成和 最大线程数相同。将最小线程数设置为其他某个值（比如1），出发点是防止系统创建太多线程，以节省系统资源

- 线程的空闲时间

  - 空闲时间应该以分钟计，而且至少在10分钟到30分钟之间

- 线程池任务大小

  - 根据业务需求进行调优。
  - 如果达到了队列数限制，再添加任务就会失败。通过 rejectedExecution 方法，处理添加任务失败的情况。

- 设置 ThreadPoolExecutor 的大小

  - 线程池的一般行为：

    > 1. 创建时准备好最小数目的线程，
    > 2. 如果来了一个任务，而此时所有的线程都在忙碌，则启动一个新线程（一直到达到最大线程数），任务就可以立即执行了。
    > 3. 否则，任务被加入等待队列，如果任务队列中已经无法加入新任务，则拒绝之。

  - 根据所选任务队列的类型，ThreadPoolExecutor 会决定何时启动一个新线程。有以下3种可能。

    - SynchronousQueue

      >  如果所有的线程都在忙碌，而且池中的线程数尚未达到最大，则新任务会启动一个新线程。
      >
      > 这个队列没办法保存等待的任务：如果来了一个任务，创建的线程数已经达到最大值，而且所有线程都在忙碌，则新的任务总是会被拒绝。
      >
      > 
      >
      > 如果只是管理少量的任务，这是个不错的选择；但是对于其他情况，就不合适了。该类文档建议将最大线程数指定为一个非常大的值，如果任务完全是CPU密集型的，这可能行得通，其他情况下可能会适得其反。另一方面，如果需要一个容易调整线程数的线程池，这种选择会更好。

    - 无界队列（如：LinkedBlockedingQueue）

      >  不会拒绝任何任务（因为队列大小没有限制）。
      >
      > 这种情况下，ThreadPoolExecutor **最多仅会按最小线程数创建线程**，也就是说，**最大线程池大小被忽略了**。
      >
      > 如果最大线程数和最小线程数相同，则这种选择和配置了固定线程数的传统线程池运行机制最为接近。

    - 有界队列（如：ArrayBlockingQueue）

      > 假设池的核心大小为4，最大为8，所用的ArrayBlockingQueue最大为10。
      >
      > 		1. 随着任务到达并被放到队列中，线程池中最多会运行4个线程（也就是核心大小）。即使队列完全填满，也就是说有10个处于等待状态的任务，ThreadPoolExecutor 也是只利用4个线程。
      > 		2. 如果队列已满，而又有新任务加进来，此时才会启动一个新线程。这里不会因为队列已满而拒绝该任务，相反，会启动一个新线程。新线程会运行队列中的第一个任务，为新来的任务腾出空间。
      >
      >  
      >
      > 该池大部分时间仅使用核心线程（4个），即使有适量的任务在队列中等待运行。这时线程池就可以用作节流阀（这是很有好处的）。如果积压的请求变得非常多，该池就会尝试运行更多线程来清理；这时第二个节流阀——最大线程数——就起作用了

  - 选用方式：

    - 可以将 ThreadPoolExecutor 的**核心线程数和最大线程数设为相同**，在保存等待任务方面，如果适合使用无界任务列表，则选择LinkedBlockingQueue；如果适合使用有界任务列表，则选择 ArrayBlockingQueue。



### ForkJoinPool

- 主要通过 fork()、join() 方法实现，用于递归、分治算法。需要花时间确定，算法中的递归任务何时结束最为合适

- 实现了工作窃取。这意味着池中的每个线程都有自己所创建任务的队列。线程会优先处理自己队列中的任务，但如果这个队列已空，它会从其他线程的队列中窃取任务。
- 一般而言，如果任务是均衡的，使用**分段的 ThreadPoolExecutor** 性能更好；而如果任务是不均衡的，则使用 ForkJoinPool 性能更好。

- 自动并行化：依赖于 ForkJoinPool 类的使用。

  - parallelStream

    - forEach() 方法将为数组列表中的每个元素创建一个任务，每个任务都会由公共的 ForkJoinTask 池处理。
    - 设置 ForkJoinTask 池的大小和设置其他任何线程池同样重要。**默认情况下，公共池的线程数等于机器上的 CPU 数。**
    - 如果在同一机器上运行着多个 JVM，则应限制这个线程数，以防这些 JVM 彼此争用CPU。

  - 设置系统属性

    ```bash
    # 设置 公共池的线程数
    -Djava.util.concurrent.ForkJoinPool.common.parallelism=N
    ```

  - 在使用 parallelStream 构造或其他自动并行化特性时，如果需要调整公共池的大小，可以考虑将所需的值减1。



### 线程同步

- 同步、CAS

  > 这段代码在一个代码块内，它们对一组变量的访问看上去是串行的，每次只有一个线程能访问内存。
  >
  > 
  >
  > 在开发者看来，最终结果看上去还是线程只能串行地访问被保护内存。

  

#### 同步的代价

- 应用在同步块上所花的时间会影响该应用的可伸缩性。
- 获取同步锁需要一些CPU周期，也会影响性能。（Java 特有，基于 Java 内存模型, JMM）
  - 非竞争
    - synchronized 锁（非膨胀锁）：开销在几百纳秒的数量级
    - CAS 开销更小
  - 竞争
    - synchronized锁（膨胀锁）：成本会随线程数增加，但每个线程所花的时间是固定的
    - CAS：当存在竞争时，开销是无法预测的
- 同步的内存语义、基于 CAS 的设施和 volatile 关键字对性能可能会有很大的影响，特别是在有很多寄存器的大型机上。





#### 避免同步

1. 在每个线程中使用不同的对象，这样访问对象时就不存在竞争了（使用 ThreadLocal）
2. 使用基于CAS的替代方案。



- 比较基于 CAS 的设施和传统的同步：
  - 如果访问的是不存在竞争的资源，那么基于 CAS 的保护要稍快于传统的同步
  - 如果访问的资源**存在轻度或适度的竞争**，那么基于 CAS 的保护要快于传统的同步（而且往往是快得多）。
  - 着所访问资源的竞争越来越剧烈，在某一时刻，传统的同步就会成为更高效的选择。在实践中，这只会出现在运行着大量线程的非常大型的机器上。
  - **当被保护的值有多个读取，但不会被写入时**，基于 CAS 的保护不会受竞争的影响。



#### 伪共享

- 如果程序访问了对象中的某个特定实例变量，则很有可能会访问邻接的实例变量。
- 不论何时，CPU 缓存中有任何数据被写入了，其他保存了同样范围数据的缓存都必须作废。



1. 对于会频繁地修改 volatile 变量或退出同步块的代码，伪共享对性能影响很大。
2. 伪共享很难检测。如果某个循环看上去非常耗时，可以检查该代码，看看是否与伪共享出现时的模式相匹配。
3. 最好通过将数据移到局部变量中、稍后再保存来避免伪共享。作为一种替代方案，有时可以使用填充将冲突的变量移到不同的缓存行中。





#### JVM  线程调优



- 偏向锁

  - 如果一个线程最近用到了某个锁，那么线程下一次执行由同一把锁保护的代码所需的数据可能仍然保存在处理器的缓存中。增加缓存命中率。
  - 默认开启

- 处理同步锁的竞争问题：

  - 自旋锁

  - 阻塞队列

    > JVM 会在这两种情况间寻求合理的平衡，自动调整将线程移交到待通知队列中之前的自旋时间。



#### 监控线程与锁

- 使用分析器（profiler）查看阻塞线程。
  - JFR + JMC
- jstack、jcmd
  - JVM 只能在特定的位置（safepoint，安全点）转储出一个线程的栈
  - 每次只能针对一个线程转储出栈信息，所以可能会看到彼此冲突的信息







## 十一、数据库性能的最佳实践



### JDBC

- JDBC 驱动程序：影响数据库应用程序性能的诸多因素中最重要的一个

  - JDBC驱动程序的实现有两种选择
    1. 胖驱动程序：在 Java 应用端（数据库的客户端）完成工作
    2. 瘦驱动程序：将工作推迟到数据库服务器端进行
  - 尽量避免使用 ODBC 和 JDBC 1型的驱动程序。

- 预处理语句(PreparedStatement)和语句池

  - 代码中若要进行JDBC调用，推荐使用PreparedStatement，尽量避免直接使用Statement。

    > 这二者的区别在于**预处理语句让数据库有机会重用已经执行过的 SQL 信息**。而这能够帮助节省之后运行的预处理语句的开销，提升执行效率。

  - 实际生产中，重用 PreparedStatement 对象才能更显著地提升性能。===> PreparedStatement 池

    - 预处理语句池基于每个连接进行工作
    - 预处理语句会消耗大量的堆空间。我们需要仔细调优语句池的大小，避免由于对大量大型对象池化而引起 GC 方面的问题。

  - 语句池的管理

    - 通过配置 JDBC 驱动程序来创建和管理语句池
    - 在应用程序代码中创建和管理语句池。

- JDBC 连接池

  - 创建数据库连接是非常耗时的操作，因此，**JDBC 连接 是 Java 程序中应该尽量重用的典型对象。**
  - 调优连接池，避免对数据库自身的性能产生负面影响。

- 事务

  - 数据库的事务有两类性能代价。
    1. 数据库事务的设置和提交都会耗费时间
    2. 数据库事务进行期间，通常事务都要对部分数据加锁
  - JDBC 事务的控制
    - 如果开启自动提交模式，则 JDBC 程序中的每个语句自身都是一个事务
    - 通过**批处理**实现的性能提升要明显高于显式地进行事务控制。
  - 事务隔离和锁（四种事务隔离模式）
    1. TRANSACTION SERIALIZABLE：要求在事务进行期间，事务涉及的所有数据都被锁定
    2. TRANSACTION REPEATABLE READ：要求事务进行期间，所有访问的数据都被锁定
    3. TRANSACTION READ COMMITTED：事务运行期间只有正在写入的行会被锁定
    4. TRANSACTION READ UNCOMMITTED：事务运行期间不会施加任何锁

- 结果集的处理

  - 需要查询处理大量数据的应用程序应该考虑增大数据提取缓冲区的大小
  - trade-off：在应用程序中载入大量的数据；还是频繁地进行数据库调用，每次获取数据集的一部分。

### JPA



#### 对 JPA 的写性能进行优化

- 尽量减少写入的字段：只更新那些已经变化的字段。
- 批量的 JPA 更新可以通过声明（在 persistence.xml 文件中）实现，也可以通过编程方式（通过调用 flush() 方法）实现



#### 对 JPA 的读性能进行优化

- JPA 会进行多种优化，以限制（或增加）一次读取操作所返回的数据量。
- JPA 实体中，如果一个大型字段（譬如 BLOB 类型的字段）很少被使用，就应该延迟载入。
- JPA 实体之间存在关系时，相关的数据可以主动载入或者延迟载入，具体的选择取决于应用程序的需要。
- 使用命名查询读取数据比普通的查询要快很多，因为 JPA 实现为命名查询构造 PreparedStatement 更容易



#### JPA 缓存

- 本地缓存：每个实体管理器实例都有自己的缓存：它会在本地缓存事务中取得的数据。
- 全局缓存（L2 Cache）：实体管理器提交事务时，本地缓存中的所有数据会合并到全局缓存中。全局缓存对应用程序的所有实体管理器而言是共享的。
- L2 缓存不会对查询返回的实体进行缓存。长期来看，这种方式有利于避免查询。
- 除非使用的 JPA 实现支持查询缓存，否则使用 JOIN 查询的效果通常会对程序的性能造成负面的效果，因为这种操作没有充分利用L2缓存。





### 最佳实践

- 通过合理配置JDBC或者JPA，尽可能地实现批量读取和写入。
- 优化应用使用的 SQL 语句。对于 JDBC 应用，这都是一些基本、标准的 SQL 命令。对 JPA 应用，还需要考虑 L2 缓存的影响。
- 尽量减少锁的使用。如果数据不大容易发生冲突，推荐使用乐观锁（OptimisticLocking）；如果数据经常发生冲突，推荐使用悲观锁（Pessimistic Locking）。
- 请务必使用预处理语句池（Prepared Statement Pool）。
- 请务必使用预处理语句池（Prepared Statement Pool）。
- 合理地设置事务的范围：由于锁在整个事务期间都需要保持，所以在不影响应用程序扩展性的前提下，尽可能把事务的范围设置得大一些。







## 十二、Java SE API 技巧



### 缓冲式 I/O

- 围绕缓冲式 I/O 有一些很常见的问题，这是由简单输入输出流类的默认实现引发的。
- 文件和 Socket 的 I/O 必须正确地缓冲，对于像压缩和字符串编解码等内部操作，也是如此



### 类加载

- 类数据（也就是 Java 字节码）通常无法快速访问到。它必须从磁盘或者网络上加载过来，必须能在 classpath 下的某个 JAR 文件中找到，还必须能在某个类加载器中找到。
- 在存在多个类加载器的复杂应用（特别是应用服务器）中，让这些类加载器支持并行，可以解决系统类加载器或者启动类加载器上的瓶颈问题。
- 如果应用是在单线程内，则通过一个类加载器加载很多类，关掉 Java 7 支持并行的特性可能会有好处。



### 随机数

- java.util.Random：Random 类的主要操作（nextGaussian()）是同步的。伪随机算法。
- java.util.concurrent. **ThreadLocalRandom**：每个线程都有自己的随机数生成器，Random 类的同步就不是问题了
- java.security.SecureRandom：SecureRandom 类使用一个系统接口来获得随机数。数据生成方式与所用的操作系统有关。SecureRandom类表现出的性能也是随意的和完全随机的。



### Java 原生接口（JNI）

- JNI 并不能解决性能问题。Java 代码几乎总是比调用原生代码跑得快。
- 当使用 JNI 时，应该限制从 Java 到 C 的调用次数；跨 JNI 边界的调用成本很高。
- 使用数组或字符串的 JNI 代码必须固定这些对象；为避免影响垃圾收集器，应该限制固定对象的时间。



### 异常

- 主要影响性能的因素：异常会涉及获取该异常发生时的栈轨迹信息。这一操作代价可能会很高，特别是在栈的轨迹很深时。

- 对于会频繁创建的系统异常，JVM 会将栈上的性能损失优化掉。

- 关闭异常中的栈轨迹信息，有时可以提高性能，不过这个过程往往会丢失一些关键信息。

- jvm 标志：

  ```bash
  # 禁止生成栈轨迹信息
  -XX:-StackTraceInThrowable
  ```

  

### 字符串的性能

- 重用字符串：intern
- 字符串编码：Java 的字符串采用的是 UTF-16 编码，而其他地方多是使用其他编码，所以将字符串编码到不同的字符集的操作很常见。
- 网络编码：在编码静态字符串（来自JSP文件等地方）时，Java EE应用服务器往往会特殊处理
- 字符串连接
  - 一行的字符串连接代码性能很不错。javac 编译器的语法糖会将其转换成使用 StringBuilder 的方式创建。
  - 对于多行的连接操作，一定要确保使用 StringBuilder。



### 日志

- 在生产代码中，GC日志（使用 -XX:+PrintGCDetails 标志开启）的开销也是非常低的，而当出现问题时，它们的好处非常大，所以GC日志应该一直打开。
- 应用日志的 3 个基本原则。
  1. 协调好要打日志的数据和所选级别（Level）之间的关系。
  2. 使用细粒度的 Logger 实例。对每个类的 Logger 实例进行配置可能会很繁琐，但这么做是值得的，因为能够更好地控制日志输出。
  3. 在向代码引入日志时，应该注意，很容易编写出带来意想不到的副作用的日志代码，即使这个日志并没有开启。



### Java 集合类 API

- 选择适合应用的算法需求的集合类。
- 设定集合的大小
  - 性能损失：
    - 集合太大，会使得垃圾收集器变慢；
    - 集合太小，又会导致大量的大小调整与复制。
  - 要减少这些性能损失，必须尽可能准确地估计一下集合最终的大小，并用这个值来构建集合。
- 集合与内存使用效率
  - 在用于保存集合中的元素的底层存储中，往往会浪费一些内存。
  - 延迟初始化技术：默认情况下（比如在调用构造函数时没有使用大小参数），这些类不再为数据分配任何底层存储，而是在向该集合中插入第一个元素时才分配。



### Lambda 表达式、Stream 和过滤器的性能

- Lambda 表达式并没有实现为类，所以有个例外情况，即当类加载行为对性能影响很大时，Lambda 表达式比匿名类略胜一筹。
- Stream 的第一个性能优势是它们被实现为了**延迟的数据结构**。
- 过滤器比迭代器性能快很多：滤器有机会使用算法优化：当完成需要做的任务时，就可以停下来，因此处理的数据较少。
- 过滤器：
  - 过滤器因为支持在迭代过程中结束处理，所以有很大的性能优势。
  - 即使都要处理整个数据集，一个过滤器还是要比一个迭代器稍微快些。
  - 多个过滤器有些开销，所以要确保编写好用的过滤器。